{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Charger tous les PDF du répertoire \"dataset/\" ===\n",
    "pdf_dir = \"dataset\"\n",
    "loaders = []\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        full_path = os.path.join(pdf_dir, filename)\n",
    "        loaders.append(PyPDFLoader(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger tous les documents depuis les PDFs\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Splitter les documents ===\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/11634806/ipykernel_3797257/3077748649.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# === 3. Embedding et vecteur store FAISS ===\n",
    "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "db = FAISS.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid model-index. Not loading eval results into CardData.\n",
      "Device set to use cuda:0\n",
      "/scratch/11634806/ipykernel_3797257/2622682682.py:13: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(\n"
     ]
    }
   ],
   "source": [
    "# === 4. Chargement du modèle de QA ===\n",
    "model_name = \"Intel/dynamic_tinybert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "question_answerer = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(\n",
    "    pipeline=question_answerer,\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Création du retriever et de la chaîne QA ===\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 56 RISK@ Cards: 42 marked with a territory and a picture of Infantry, Cavalry, or \n",
      "Artillery l 2 “wild” cards marked with all three pictures, but no territory l 12 Secret \n",
      "Mission cards used only in Secret Mission Risk, page 13. \n",
      "OBJECT OF THE GAME To conquer the world by occupying every territory on the board, \n",
      "thus eliminating all your opponents. \n",
      "SETUP Unlike most games, RISK demands careful planning before you actually start to \n",
      "play. This Initial Army Placement sets the stage for the battles you’ll fight later on. \n",
      "INITIAL ARMY PLACEMENT consists of these steps: 1. 2. 3. 4. Select a color and, \n",
      "depending on the number of players, count out the “armies” you’ll need to start the \n",
      "game. If 2 are playing, see instructions on page 11. If 3 are playing, each player counts \n",
      "out 35 Infantry. If 4 are playing, each player counts out 30 Infantry. If 5 are playing, each \n",
      "player counts out 25 Infantry. If 6 are playing, each player counts out 20 Infantry. Roll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/ulc/cursos/curso341/transformers3/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === 6. Question test ===\n",
    "question = \"What is the name of the game?\"\n",
    "\n",
    "def err_remove(er):\n",
    "    lin = \"------------\"\n",
    "    er = str(er)\n",
    "    start_index = er.find(lin) + len(lin)\n",
    "    end_index = er.rfind(lin)\n",
    "    Answer = er[start_index:end_index].strip()\n",
    "    return Answer\n",
    "\n",
    "try:\n",
    "    result = qa.invoke({\"query\": question})\n",
    "    print(result[\"result\"])\n",
    "except:\n",
    "    _, error, _ = sys.exc_info()\n",
    "    answer = err_remove(error)\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers3",
   "language": "python",
   "name": "transformers3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
